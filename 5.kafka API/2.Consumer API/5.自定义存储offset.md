# 5. 自定义提交 offset

kafka 0.9版本之前，offset存储在 zookeeper，0.9版本后 offset存储在kafka内1个内置的 topic中。

除此之外，kafka还可以选择自定义存储 offset。

## 5.1 消费者的 Rebalance

offset的维护是相当繁琐的，因为需要考虑到消费者的 Rebalance。

### Rebalance 触发条件

当有新的消费者加入消费组、已有的消费者退出消费组 或 所订阅的主题的分区发生变化，就会触发到分区的重新分配，重新分配的过程叫 Rebalance。

消费者发生 Rebalance之后，每个消费者消费的分区就会发生变化。因此消费者要首先获取到自己被重新分配到的分区，并且定位到每个分区最近提交的 offset位置继续消费。


## 5.2 实现自定义存储 offset

要实现自定义存储 offset，需要借助 `ConsumerRebalanceListener`类，其中提交和获取 offset的方法，需要根据所选 offset存储系统自行实现。

> 使用场景: offset保存 和 mysql存储数据 组成1个事务。

### java 实现

```java
package com.atguigu.kafka.consumer

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.TopicPartition;

import java.util.*;

public class CustomerConsuer {
    private static Map<TopicPartition, Long> currentOffset = new HashMap<>();

    public static void main(String[] args){
        //创建配置信息
        Properties props = new Properties();

        //Kafka集群
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        
        //关闭自动提交
        props.put(ConsumerConfig.ENABEL_AUTO_COMMIT_CONFIG, false);   

        //消费者组
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "bigdata");
        
        //Key, Value的反序列化
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");
        
        //创建1个消费者
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        
        //消费者订阅主题
        consumer.subscribe(Arrays.asList("first"), new ConsumerRebalanceListener() {
            //该方法会在 Rebalance之前调用
            @override
            public onPartitionsRevoked(Collection<TopicPartition> partitions){
                // 查找该分区之前的 offset，并保存下来
                commitOffset(cunrrentOffset);
            }
            
            //该方法会在 Rebalance之后调用
            @override
            public onPartitionAssigned(Collection<TopicPartition> partitions){
                currentOffset.clear();
                for (TopicPartition partition: partitions){
                    // 接着人家之前的offset消费
                    consumer.seek(partition, getOffset(partition));// 定位到最近提交的 offset位置继续消费
                }
            }
        })
    }
    

    // 自定义实现: 获取某分区的最新offset
    private static long getOffset(TopicPartiton partition){
        return 0
    }
    
    // 自定义实现: 提交该消费者所有分区的offset
    private static long commitOffset(Map<TopicPartiton, Long>currentOffset){
            return 0
    }
}
```

### Python 实现
